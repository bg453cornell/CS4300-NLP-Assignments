{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cf2de1033a0be1ead7804c8053dfde6",
     "grade": false,
     "grade_id": "cell-05fb407e20c068e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4: \"Search your transcripts. You will know it to be true.\" (Part 2)\n",
    "\n",
    "## Â© Cristian Danescu-Niculescu-Mizil 2018\n",
    "\n",
    "## CS/INFO 4300 Language and Information\n",
    "\n",
    "### Due by midnight on Wednesday February 28th\n",
    "\n",
    "\n",
    "This is an **individual** assignment.\n",
    "\n",
    "If you use any outside sources (e.g. research papers, StackOverflow) please list your sources.\n",
    "\n",
    "In this assignment we will explore the tradeoffs of information retrieval systems by finding newspaper quotes from \"Keeping Up With The Kardashians\".\n",
    "\n",
    "**Guidelines**\n",
    "\n",
    "All cells that contain the blocks that read `# YOUR CODE HERE` are editable and are to be completed to ensure you pass the test-cases. Make sure to write your code where indicated.\n",
    "\n",
    "All cells that read `YOUR ANSWER HERE` are free-response cells that are editable and are to be completed.\n",
    "\n",
    "You may use any number of notebook cells to explore the data and test out your functions, although you will only be graded on the solution itself.\n",
    "\n",
    "\n",
    "You are unable to modify the read-only cells.\n",
    "\n",
    "You should also use Markdown cells to explain your code and discuss your results when necessary.\n",
    "Instructions can be found [here](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "All floating point values should be printed with **2 decimal places** precision. You can do so using the built-in round function.\n",
    "\n",
    "**Grading**\n",
    "\n",
    "For code-completion questions you will be graded on passing the public test cases we have included, as well as any hidden test cases that we have supplemented to ensure that your logic is correct.\n",
    "\n",
    "For free-response questions you will be manually graded on the quality of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c2fdf75e29b995a1aa17b885863306dc",
     "grade": false,
     "grade_id": "cell-30f8447c4e8aec09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Find the most similar messages (cosine similarity)\n",
    "\n",
    "### A high-level overview\n",
    "\n",
    "Our overall goal of the last part of this assignment is to build a system where we can compute the cosine similarity between queries and our datasets quickly. To accomplish queries and compute cosine similarities, we will need to represent documents as vectors. A common method of representing documents as vectors is by using \"term frequency-inverse document frequency\" scores. More details about this method can be found [on the course website](http://www.cs.cornell.edu/courses/cs4300/2018sp/Slides//vsm_cheatsheet.pdf). The notation here is consistent with the hand out, so if you haven't read over it -- you should!\n",
    "\n",
    "Consider the tf-idf representation of a document and a query: $\\vec{d_j}$ and $\\vec{q}$, respectively. Elements of these vectors are very often zero because the term frequency of most words in most documents is zero. Stated differently, most words don't appear in most documents! Consider a query that has 5 words in it and a vocabulary that has 20K words in it -- only .025% of the elements of the vector representation of the query are nonzero! When a vector (or a matrix) has very few nonzero entries, it is called \"sparse.\" We can take advantage of the sparsity of tf-idf document representations to compute cosine similarity quickly. We will first build some data stuctures that allow for faster querying of statistics, and then we will build a function that quickly computes cosine similarity between queries and documents.\n",
    "\n",
    "### A starting point\n",
    "We will use an **inverted index** for efficiency. This is a sparse term-centered representation that allows us to quickly find all documents that contain a given term.\n",
    "\n",
    "### Q1 Write a function to construct the index.\n",
    "\n",
    "As in class, the index is a key-value structure where the keys are terms and the values are lists of *postings*. In this case, like in class, we record the documents a term occurs in as well as the **count** of that term in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6bb06aa34fd152ca30507dea5e8f1638",
     "grade": false,
     "grade_id": "cell-80fc97f06dc7715b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"kardashian-transcripts.json\", \"r\") as f:\n",
    "    transcripts = json.load(f)\n",
    "print(len(transcripts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b1a795b831ab818b582e77a021c6bae",
     "grade": false,
     "grade_id": "cell-ad3a994ca18d709b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "flat_msgs = [m for transcript in transcripts for m in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eb181eea78ea167263c55cc3c5592693",
     "grade": false,
     "grade_id": "cell-977931635a8ef8aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "54063a104eb20ded23a4592065fb60a4",
     "grade": false,
     "grade_id": "build_inverted_index",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_inverted_index(msgs):\n",
    "    \"\"\" Builds an inverted index from the messages.\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    \n",
    "    msgs: list of dicts.\n",
    "        Each message in this list already has a 'toks'\n",
    "        field that contains the tokenized message.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    index: dict\n",
    "        For each term, the index contains a list of\n",
    "        tuples (doc_id, count_of_term_in_doc):\n",
    "        index[term] = [(d1, tf1), (d2, tf2), ...]\n",
    "        \n",
    "    Example\n",
    "    =======\n",
    "    \n",
    "    >> test_idx = build_inverted_index([\n",
    "    ...    {'toks': ['to', 'be', 'or', 'not', 'to', 'be']},\n",
    "    ...    {'toks': ['do', 'be', 'do', 'be', 'do']}])\n",
    "    \n",
    "    >> test_idx['be']\n",
    "    [(0, 2), (1, 2)]\n",
    "    \n",
    "    >> test_idx['not']\n",
    "    [(0, 1)]\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    index = {}\n",
    "    for i in range(len(msgs)):\n",
    "        for word in set(msgs[i]['toks']):\n",
    "            cnt = msgs[i]['toks'].count(word)\n",
    "            if word not in index.keys():\n",
    "                index[word] = [(i, cnt,)]\n",
    "            else:\n",
    "                index[word].append((i, cnt,))\n",
    "    return index\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8594136bc3e95b1cf6f7e97e396f4cde",
     "grade": true,
     "grade_id": "build_inverted_index_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "start_time = time.time()\n",
    "inv_idx = build_inverted_index(flat_msgs)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "assert len(inv_idx['bruce']) >= 385 and len(inv_idx['bruce']) <= 435\n",
    "assert len(inv_idx['baby']) >= 250 and len(inv_idx['baby']) <= 300\n",
    "assert execution_time <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a057407e712e7784112fa3b7e4a3d8c",
     "grade": false,
     "grade_id": "cell-1d10f0b8dc4ffc19",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q2 Compute IDF *using* the inverted index\n",
    "\n",
    "Write a function `compute_idf` that uses the inverted index to efficiently compute IDF values.\n",
    "\n",
    "Words that occur in a very small number of documents are not useful in many cases, so we ignore them. Use a parameter `min_df`\n",
    "to ignore all terms that occur in strictly fewer than `min_df=10` documents.\n",
    "\n",
    "Similarly, words that occur in a large *fraction* of the documents don't bring any more information for some tasks. Use a parameter `max_df_ratio` to trim out such words. For example, `max_df_ratio=0.95` means ignore all words that occur in more than 95% of the documents.\n",
    "\n",
    "As a reminder, we define the IDF statistic as...\n",
    "$$ IDF(t) = \\log \\left(\\frac{N}{1 + DF(t)} \\right) $$\n",
    "\n",
    "where N is the total number of docs and $DF(t)$ is the number of docs containing $t$. Keep in mind, there are other definitions if IDF out there, so if you go looking for resources on the internet, you might find differing (but also valid) accounts. The base of the log can be taken to be 2 (though the base doesn't really matter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "78e20d16baeb129de971279a99c29b70",
     "grade": false,
     "grade_id": "compute_idf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_idf(inv_idx, n_docs, min_df=10, max_df_ratio=0.95):\n",
    "    \"\"\" Compute term IDF values from the inverted index.\n",
    "    \n",
    "    Words that are too frequent or too infrequent get pruned.\n",
    "    \n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    \n",
    "    inv_idx: an inverted index as above\n",
    "    \n",
    "    n_docs: int,\n",
    "        The number of documents.\n",
    "        \n",
    "    min_df: int,\n",
    "        Minimum number of documents a term must occur in.\n",
    "        Less frequent words get ignored.\n",
    "    \n",
    "    max_df_ratio: float,\n",
    "        Maximum ratio of documents a term can occur in.\n",
    "        More frequent words get ignored.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    idf: dict\n",
    "        For each term, the dict contains the idf value.\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    idf = {}\n",
    "    for term, postings in inv_idx.items():\n",
    "        if len(postings) < min_df or (len(postings)+0.)/n_docs > max_df_ratio:\n",
    "            continue\n",
    "        else:\n",
    "            idf[term] = np.log2(n_docs/(1.0+len(postings)))\n",
    "    return idf\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "de4c950562bfbacf8a3e207f1b3302d4",
     "grade": true,
     "grade_id": "compute_idf_test",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "start_time = time.time()\n",
    "idf_dict = compute_idf(inv_idx, len(flat_msgs))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "assert idf_dict['bruce'] >= 6.0 and idf_dict['bruce'] <= 7.0\n",
    "assert idf_dict['baby'] >= 6.0 and idf_dict['baby'] <= 8.0\n",
    "assert execution_time <= 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "331c64023b0a35781ae9b726b4042289",
     "grade": false,
     "grade_id": "cell-976a9144b11db274",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q3 Compute the norm of each document using the inverted index\n",
    "\n",
    "Recalling our tf-idf vector representation of documents, we can compute the \"norm\" as the norm (length) of the vector representation of that document. More specifically, the norm of a document $j$, denoted as $\\left|\\left| d_j \\right|\\right|$, is given as follows...\n",
    "\n",
    "$$ \\left|\\left| d_j \\right|\\right| = \\sqrt{\\sum_{\\text{word } i} (tf_{ij} \\cdot idf_i)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "881f76fc025a8f6d4c5c516471c553db",
     "grade": false,
     "grade_id": "compute_doc_norms",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_doc_norms(index, idf, n_docs):\n",
    "    \"\"\" Precompute the euclidean norm of each document.\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    \n",
    "    index: the inverted index as above\n",
    "    \n",
    "    idf: dict,\n",
    "        Precomputed idf values for the terms.\n",
    "    \n",
    "    n_docs: int,\n",
    "        The total number of documents.\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    norms: np.array, size: n_docs\n",
    "        norms[i] = the norm of document i.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    norms = np.zeros(n_docs)\n",
    "    for term, idf_i in idf.items():\n",
    "        doc_id, freq = zip(*index[term])\n",
    "        tf_idf = np.square(idf_i * np.array(freq))\n",
    "        for k in range(len(doc_id)):\n",
    "            norms[doc_id[k]] += tf_idf[k]\n",
    "    norms = np.sqrt(norms)\n",
    "    return norms\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f04a3be8e0324923e8ea7b76b6291c6b",
     "grade": true,
     "grade_id": "compute_doc_norms_test",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "start_time = time.time()\n",
    "doc_norms = compute_doc_norms(inv_idx, idf_dict, len(flat_msgs))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "assert doc_norms[1] >= 15.5 and doc_norms[1] <= 17.5\n",
    "assert doc_norms[5] >= 6.5 and doc_norms[5] <= 8.5\n",
    "assert execution_time <= 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e42c79a82743a498adb989ddbb5060a",
     "grade": false,
     "grade_id": "cell-7fef1edededcee58",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q4 Find the most similar messages to the quotes.  Write the `index_search` function.\n",
    "\n",
    "The goal of this section is to implement index_search, a fast implementation of cosine similarity. Next, you can test your answer by running the search using the code provided. Briefly discuss why it worked, or why it might not have worked, for each query.\n",
    "\n",
    "The goal of index_search is to compute the cosine similarity between the query and each document in the dataset. Naively, this computation requires you to compute dot products between the query tf-idf vector $q$ and each document's tf-idf vector $d_i$.\n",
    "\n",
    "However, you should be able to use the sparsity of the tf-idf representation and the data structures you created to your advantage. More specifically, consider the cosine similarity...\n",
    "\n",
    "$$ cossim(\\vec{q}, \\vec{d_j}) = \\frac{\\vec{q} \\cdot \\vec{d_j}}{\\|\\vec{q}\\| \\cdot \\|\\vec{d_j}\\|}$$\n",
    "\n",
    "Specifically, focusing on the numerator...\n",
    "\n",
    "$$ \\vec{q} \\cdot \\vec{d_j} = \\sum_{i} {q_i} * {d_i}_j $$\n",
    "\n",
    "Here ${q_i}$ and ${d_i}_j$ are the $i$-th dimension of the vectors $q$ and ${d_j}$ respectively.\n",
    "Because many ${q_i}$ and ${d_i}_j$ are zero, it is actually a bit wasteful to actually create the vectors $q$ and $d_j$ as numpy arrays; this is the method that you saw in class.\n",
    "\n",
    "A faster approach to computing the numerator term of cosine similarity involves quickly computing the above summation using the inverted index, pre-computed idf scores, and pre-computed document norms.\n",
    "\n",
    "A good \"first step\" to implementing this efficiently is to only loop over ${q}_j$ that are nonzero (i.e. ${q}_j$ such that the word $j$ appears in the query). \n",
    "\n",
    "**Note** Convert the query to lowercase, and use the `nltk.tokenize.TreebankWordTokenizer` to tokenize the query. The transcripts have already been tokenized this way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "90699192b6af5694100091a1563ad058",
     "grade": false,
     "grade_id": "cell-b39f99a59a119d67",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Aside:** Precomputation\n",
    "\n",
    "In many settings, we will need to repeat the same kind of operation many times. Often, part of the input doesn't change.\n",
    "Queries against the Kardashians transcript are like this: we want to run more queries (in the real world we'd want to run a lot of them every second, even) but the data we are searching doesn't change.\n",
    "\n",
    "We could write an `index_search` function with the same signature as `verbatim_search`, taking the `query` and the `msgs` as input, and the function would look like:\n",
    "\n",
    "    def index_search(query, msgs):\n",
    "        inv_idx = build_inverted_index(msgs)\n",
    "        idf = compute_idf(inv_idx, len(msgs))\n",
    "        doc_norms = compute_doc_norms(inv_idx)\n",
    "        # do actual search\n",
    "\n",
    "\n",
    "But notice that the first three lines only depend on the messages. Imagine if we run this a million times with different queries but the same collection of documents: we'd wastefully recompute the index, the IDFs and the norms every time and discard them. It's a better idea, then, to precompute them just once, and pass them as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "336eff44e5e26f2f323ea5a8c8549ef0",
     "grade": false,
     "grade_id": "cell-ef81cb8deedd1818",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "queries = [u\"It's like a bunch of people running around talking about nothing.\",\n",
    "           u\"Never say to a famous person that this possible endorsment would bring 'er to the spot light.\",\n",
    "           u\"Your yapping is making my head ache!\",\n",
    "           u\"I'm going to Maryland, did I tell you?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94f16111f94539105aa62a3cc75c7907",
     "grade": false,
     "grade_id": "cell-9f5e36e0536c8e91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "inv_idx = build_inverted_index(flat_msgs)\n",
    "\n",
    "idf = compute_idf(inv_idx, len(flat_msgs),\n",
    "                  min_df=10,\n",
    "                  max_df_ratio=0.1)  # documents are very short so we can use a small value here\n",
    "                                     # examine the actual DF values of common words like \"the\"\n",
    "                                     # to set these values\n",
    "\n",
    "inv_idx = {key: val for key, val in inv_idx.items()\n",
    "           if key in idf}            # prune the terms left out by idf\n",
    "\n",
    "doc_norms = compute_doc_norms(inv_idx, idf, len(flat_msgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37f1b22507a77d5d3b996b858c38a88e",
     "grade": false,
     "grade_id": "cell-948817729d039357",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'more', 'general-purpose', 'tokenizer']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(\"a more general-purpose tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2c4e0b7bef3869173f741fdb1310407b",
     "grade": false,
     "grade_id": "index_search",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def index_search(query, index, idf, doc_norms):\n",
    "    \"\"\" Search the collection of documents for the given query\n",
    "    \n",
    "    Arguments\n",
    "    =========\n",
    "    \n",
    "    query: string,\n",
    "        The query we are looking for.\n",
    "    \n",
    "    index: an inverted index as above\n",
    "    \n",
    "    idf: idf values precomputed as above\n",
    "    \n",
    "    doc_norms: document norms as computed above\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    results, list of tuples (score, doc_id)\n",
    "        Sorted list of results such that the first element has\n",
    "        the highest score, and `doc_id` points to the document\n",
    "        with the highest score.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    results = np.array([0. for i in range(len(doc_norms))])\n",
    "    q = tokenizer.tokenize(query.lower())\n",
    "    q_tf = {term: q.count(term) for term in set(q)}\n",
    "    # Compute q_norm\n",
    "    q_norm = 0.\n",
    "    for term, tf in q_tf.items():\n",
    "        if term in idf.keys():\n",
    "            q_norm += (tf*idf[term])**2\n",
    "    q_norm = np.sqrt(q_norm)\n",
    "    if q_norm != 0.:\n",
    "        # Compute cosine similarity\n",
    "        for term_i, tf_qi in q_tf.items():\n",
    "            if term_i in idf.keys():\n",
    "                doc_id, tf = zip(*index[term_i])\n",
    "                numerator_array = tf_qi * idf[term_i]**2 * np.array(tf)\n",
    "                for k in range(len(doc_id)):\n",
    "                    results[doc_id[k]] += numerator_array[k]\n",
    "        res = [results[i]/(q_norm * doc_norms[i]) if results[i] != 0. and doc_norms[i] != 0. else 0.\\\n",
    "               for i in range(len(results))]\n",
    "        res = list(zip(res, range(len(res))))\n",
    "        return sorted(res, key = lambda x: x[0], reverse = True)\n",
    "    else:\n",
    "        return list(zip(results, range(len(results))))\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec7c84ba5a7560acb7316a99a3bde3be",
     "grade": true,
     "grade_id": "index_search_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "It's like a bunch of people running around talking about nothing.\n",
      "#################################################################\n",
      "[1.00] BRUCE: It's like a bunch of people running around talking about nothing.\n",
      "\t(Keeping Up With the Kardashians - Kourt's First Cover)\n",
      "[0.61] KRIS: It's not a bunch of teenagers running around.\n",
      "\t(Keeping Up With the Kardashians - Kris ``The Cougar'' Jenner)\n",
      "[0.46] ROB: I have a bunch of connections in the industry.\n",
      "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
      "[0.46] ROB: I have a bunch of connections in the industry.\n",
      "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
      "[0.43] KHLOE: She's, like, running.\n",
      "\t(Keeping Up With the Kardashians - Match Made in Hell)\n",
      "[0.42] ROB: She got me a bunch of interviews.\n",
      "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
      "[0.42] ROB: She got me a bunch of interviews.\n",
      "\t(Keeping Up With the Kardashians - Must Love Dogs)\n",
      "[0.41] KHLOE: Not running.\n",
      "\t(Keeping Up With the Kardashians - The Missing Ring)\n",
      "[0.41] KOURTNEY: We don't want a bunch of on the counter.\n",
      "\t(Keeping Up With the Kardashians - All for One and One for Kim)\n",
      "[0.40] JOSIE: He cowrote a bunch of the big hits.\n",
      "\t(Keeping Up With the Kardashians - The Kardashians Take NYC)\n",
      "\n",
      "#############################################################################################\n",
      "Never say to a famous person that this possible endorsment would bring 'er to the spot light.\n",
      "#############################################################################################\n",
      "[0.44] ROB: With a light,crispy panko breading.\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.44] ROB: With a light,crispy panko breading.\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.44] ROB: With a light,crispy panko breading.\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.41] KHLOE: You've never blasted outdual-LED light then sucked in everydetail in 8-Megapixels.\n",
      "\t(Keeping Up With the Kardashians - All for One and One for Kim)\n",
      "[0.40] SIMON: Make light of this and have dessert.\n",
      "\t(Keeping Up With the Kardashians - What's Yours Is Mine)\n",
      "[0.38] KIM: Bring a d ofash.\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.38] KIM: Bring a d ofash.\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.38] WOMAN: Bring it.\n",
      "\t(The Wedding: Keeping Up With the Kardashians)\n",
      "[0.38] KIM: Bring a d ofash.\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.37] KOURTNEY: I say we load up thebÃ©bÃ©;I'll bring this and this.\n",
      "\t(Keeping Up With the Kardashians - Leaving the Nest)\n",
      "\n",
      "####################################\n",
      "Your yapping is making my head ache!\n",
      "####################################\n",
      "[0.69] SCOTT: The head!\n",
      "\t(Keeping Up With the Kardashians - Delivering Baby Mason)\n",
      "[0.52] DOCTOR: So here's the head.\n",
      "\t(Keeping Up With the Kardashians - Blame It on the Alcohol)\n",
      "[0.52] NURSE: His head is out.\n",
      "\t(Keeping Up With the Kardashians - Delivering Baby Mason)\n",
      "[0.52] KHLOE: His head is out.\n",
      "\t(Keeping Up With the Kardashians - Blame It on the Alcohol)\n",
      "[0.52] NURSE: His head is out.\n",
      "\t(Keeping Up With the Kardashians - Blame It on the Alcohol)\n",
      "[0.50] KHLOE: I'm making a unicorn.\n",
      "\t(Keeping Up With the Kardashians - The Missing Ring)\n",
      "[0.50] LAMAR: I'm making a sandwich.\n",
      "\t(Keeping Up With the Kardashians - The Missing Ring)\n",
      "[0.48] KIM: Your whole head is gray.\n",
      "\t(Keeping Up With the Kardashians - My Bodyguard)\n",
      "[0.48] BRUCE: Don't let anything go to your head.\n",
      "\t(Keeping Up With the Kardashians - Kim Becomes a Diva)\n",
      "[0.47] KOURTNEY: And that is not where my head is at at all.\n",
      "\t(Keeping Up With the Kardashians - Kim Becomes a Diva)\n",
      "\n",
      "######################################\n",
      "I'm going to Maryland, did I tell you?\n",
      "######################################\n",
      "[1.00] BRUCE: Did I tell you I'm going to maryland?\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.74] ROB: I'm going to tell her.\n",
      "\t(Keeping Up With the Kardashians - Meet the Kardashians)\n",
      "[0.70] ADRIENNE: What did I just tell you?\n",
      "\t(Keeping Up With the Kardashians - Kim Becomes a Diva)\n",
      "[0.60] BRUCE: Why didn't you tell me?\n",
      "\t(Keeping Up With the Kardashians - The Wedding)\n",
      "[0.60] BRUCE: Why didn't you tell me?\n",
      "\t(The Wedding: Keeping Up With the Kardashians)\n",
      "[0.58] BRUCE: What else did Stevens tell you?\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.56] FRIEND: I'm going to .\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.56] FRIEND: I'm going to .\n",
      "\t(Keeping Up With the Kardashians - Shape Up or Ship Out)\n",
      "[0.56] KOURTNEY: I'm going.\n",
      "\t(Keeping Up With the Kardashians - Kim Becomes a Diva)\n",
      "[0.56] KHLOE: I'm going to barf.\n",
      "\t(Keeping Up With the Kardashians - You Are So Pregnant Dude)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is an autograder test. Here we can test the function you just wrote above.\n",
    "start_time = time.time()\n",
    "score, _ = index_search(queries[1], inv_idx, idf, doc_norms)[0]\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "assert score >= 0.38 and score <= 0.48\n",
    "assert execution_time <= 0.5\n",
    "\n",
    "\n",
    "for query in queries:\n",
    "    print(\"#\" * len(query))\n",
    "    print(query)\n",
    "    print(\"#\" * len(query))\n",
    "\n",
    "    for score, msg_id in index_search(query, inv_idx, idf, doc_norms)[:10]:\n",
    "        print(\"[{:.2f}] {}: {}\\n\\t({})\".format(\n",
    "            score,\n",
    "            flat_msgs[msg_id]['speaker'],\n",
    "            flat_msgs[msg_id]['text'],\n",
    "            flat_msgs[msg_id]['episode_title'])) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3deb5238156b07afc15b2c75d65e024f",
     "grade": false,
     "grade_id": "cell-f79bce72b4282bde",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Briefly discuss why it worked, or why it might not have worked, for each query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a19caaed798f475711d44847abad17b1",
     "grade": true,
     "grade_id": "index_search_ans",
     "locked": false,
     "points": 15,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The code above worked for the first and the fourth query because the top result matches every single word in the query. For the second and third query, it might not have worked because documents that match more words have lower scores, and the results seem to be not quite relevant to our queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da98dfed1d52410be3b48559559ccc46",
     "grade": false,
     "grade_id": "cell-6cbbf6d5e1dd4da8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q5EC: Bonus question 1 for extra course credit.\n",
    "\n",
    "### Updating precomputed values.\n",
    "\n",
    "In many real-world applications, the collection of documents will not stay the same forever. At Internet-scale, however, it could possibly even be worth recomputing things every second, if during that second we're going to answer millions of queries.\n",
    "\n",
    "However, there's a better way: in reality, the document set will not change radically, but incrementally.  In particular, it's most common to add or remove a bunch of new documents to the index.\n",
    "\n",
    "Write functions `add_docs` and `remove_docs` that update the index, idf and document norms.  Think of the implications this has on how we store the IDF. Is there a better way of storing it, that minimizes the memory we need to touch when updating?\n",
    "\n",
    "Think of adequate test cases for these functions and implement them.\n",
    "\n",
    "**Note:** You can get up to 0.5 EC for completing this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0a44b8ec72f9b03c736614d5c478a6e9",
     "grade": true,
     "grade_id": "extra_credit_1",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def add_docs(new_docs, msgs, index, compute_idf, compute_doc_norms):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    new_docs: list of dicts\n",
    "    msgs: list of dicts\n",
    "    index: dict\n",
    "    compute_idf: function, compute_idf(inv_idx, n_docs, min_df=10, max_df_ratio=0.95)\n",
    "    compute_doc_norms: def compute_doc_norms(index, idf, n_docs)\n",
    "    return: \n",
    "    index: dict\n",
    "    idf: dict\n",
    "    doc_norms: numpy array\n",
    "    \"\"\"\n",
    "    msgs.extend(new_docs)\n",
    "    \n",
    "    # Update inversed index\n",
    "    for i in range(len(msgs)-len(new_docs), len(msgs)):\n",
    "        for term in set(msgs[i]['toks']):\n",
    "            cnt = msgs[i]['toks'].count(term)\n",
    "            if term not in index.keys():\n",
    "                index[term] = [(i, cnt,)]\n",
    "            else:\n",
    "                index[term].append((i, cnt,))\n",
    "    # Update idf\n",
    "    new_idf = compute_idf(index, len(msgs), min_df=10, max_df_ratio=0.95)\n",
    "    # Update doc_norms\n",
    "    new_doc_norms = compute_doc_norms(index, new_idf, len(msgs))\n",
    "    return index, new_idf, new_doc_norms\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inv_idx, new_idf, new_doc_norms = \\\n",
    "add_docs(flat_msgs[0:3], flat_msgs, inv_idx, compute_idf, compute_doc_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(flat_msgs) == 39681\n",
    "assert new_doc_norms[-3] > 17.0 and new_doc_norms[-3] < 18.0\n",
    "assert new_doc_norms[-2] > 16.0 and new_doc_norms[-2] < 16.5\n",
    "assert new_doc_norms[-1] > 4.0 and new_doc_norms[-1] < 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_docs(rm_docs, msgs, index, compute_idf, compute_doc_norms):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    rm_docs: list of doc_id to be removed\n",
    "    msgs: list of dicts\n",
    "    index: dict\n",
    "    compute_idf: function, compute_idf(inv_idx, n_docs, min_df=10, max_df_ratio=0.95)\n",
    "    compute_doc_norms: def compute_doc_norms(index, idf, n_docs)\n",
    "    return: \n",
    "    index: dict\n",
    "    idf: dict\n",
    "    doc_norms: numpy array\n",
    "    \"\"\"\n",
    "    # Update inversed index\n",
    "    for i in rm_docs:\n",
    "        for term in set(msgs[i]['toks']):\n",
    "            if term in index.keys():\n",
    "                doc_id, _ = zip(*index[term])\n",
    "                if i in doc_id:\n",
    "                    rm_idx = doc_id.index(i)\n",
    "                    index[term].pop(rm_idx)\n",
    "    # Delete docs\n",
    "    for j in sorted(rm_docs, reverse = True):\n",
    "        msgs.pop(j)\n",
    "    # Update idf\n",
    "    rm_idf = compute_idf(index, len(msgs), min_df=10, max_df_ratio=0.95)\n",
    "    # Update doc_norms\n",
    "    rm_doc_norms = compute_doc_norms(index, rm_idf, len(msgs))\n",
    "    return index, rm_idf, rm_doc_norms\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_inv_idx, rm_idf, rm_doc_norms = \\\n",
    "remove_docs([39678, 39679, 39680], flat_msgs, new_inv_idx, compute_idf, compute_doc_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(flat_msgs) == 39678\n",
    "assert rm_doc_norms[0] > 17.5 and rm_doc_norms[0] < 18.0\n",
    "assert rm_doc_norms[1] > 16.0 and rm_doc_norms[1] < 16.5\n",
    "assert rm_doc_norms[2] > 4.4 and rm_doc_norms[2] < 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0c6ff47c36239f69447edfda31f8229f",
     "grade": false,
     "grade_id": "cell-bbbf1b05f86579fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q6EC: Bonus question 2 for extra course credit.\n",
    "\n",
    "### Finding your own similarity metric\n",
    "\n",
    "We've explored using cosine similarity and edit distance to find similar messages to input queries. However, there's a whole world of ways to measure the similarity between two documents. Go forth, and research!\n",
    "\n",
    "For this question, find a new way of measuring similarity between two documents, and implement a search using your new metric. Your new way of measuring document similarity should be different enough from the two approaches we already implemented. It can be a method you devise or an existing method from somewhere else.\n",
    "\n",
    "**Note:** The amount of EC awarded for this question will be determined based on creativity, originality, implementation, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6256ee60a590b4e555a167d189281028",
     "grade": true,
     "grade_id": "extra_credit_2",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
